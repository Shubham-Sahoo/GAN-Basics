{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOoErJLGlM/i/gIdLAB6gLe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubham-Sahoo/GAN-Basics/blob/main/GAN_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "PE-Kqr5-gJUS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transformation to apply to the images (e.g., convert to tensor)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])  # scale to [-1, 1]\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of test samples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "ZF2lcdYpgK6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de32afbb-5728-4889-d5a3-84e4ead26ef4"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 60000\n",
            "Number of test samples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_dataset:\n",
        "    print(x[0].shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwQPQl7QpUpw",
        "outputId": "c9a8e09d-57a7-40e6-8cfe-380499cb1d19"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, img_channels=1, feature_maps=64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.latent_linear = nn.Linear(latent_dim, feature_maps * 7*7)\n",
        "        self.unflatten = nn.Unflatten(1, (feature_maps, 7, 7))\n",
        "        self.conv_up1 = nn.ConvTranspose2d(feature_maps, feature_maps // 2, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv_up2 = nn.ConvTranspose2d(feature_maps // 2, img_channels, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "        self.relu1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.relu2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.tanh1 = nn.Tanh()\n",
        "\n",
        "        self.batchnorm1 = nn.BatchNorm2d(feature_maps // 2)\n",
        "\n",
        "\n",
        "    def forward(self, z):\n",
        "\n",
        "        out = self.latent_linear(z)\n",
        "        out = self.relu1(out)\n",
        "        out = self.unflatten(out)\n",
        "\n",
        "        out = self.conv_up1(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.batchnorm1(out)\n",
        "\n",
        "        out = self.conv_up2(out)\n",
        "        out = self.tanh1(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fej6Qm6Lg9rY"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = Generator(100, 1, 64)\n",
        "x = torch.tensor(np.ones((1,100)), dtype=torch.float)\n",
        "G(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZx56X7jjlHj",
        "outputId": "7a6d32e5-63f8-4a75-cb15-74461887db55"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_channels=1, feature_maps=64):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, feature_maps, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(feature_maps, feature_maps*2, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(feature_maps*2*7*7, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "3oguQ4V0hsaa"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator(1, 64)\n",
        "x = torch.tensor(np.ones((3,1,28,28)), dtype=torch.float)\n",
        "D(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yun_LQ_bjkVN",
        "outputId": "e1137199-4fb5-421b-d677-8a0d3e0ead11"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generated_images(generator, noise, epoch, out_dir=\"gan_outputs\"):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        fake_images = generator(noise).cpu()\n",
        "\n",
        "    # For 1D vectors (e.g., Gaussian): Plot as line chart\n",
        "    if fake_images.dim() == 2:  # Shape: [batch_size, features]\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        for i in range(min(8, fake_images.size(0))):\n",
        "            plt.plot(fake_images[i].numpy(), label=f\"Sample {i}\")\n",
        "        plt.title(f\"Generated Samples at Epoch {epoch}\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{out_dir}/epoch_{epoch}_lines.png\")\n",
        "        plt.close()\n",
        "\n",
        "    # For image data (e.g., MNIST or CIFAR): Show grid\n",
        "    elif fake_images.dim() == 4:  # Shape: [B, C, H, W]\n",
        "        from torchvision.utils import make_grid\n",
        "        grid = make_grid(fake_images, nrow=4, normalize=True, value_range=(-1, 1))\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(grid.permute(1, 2, 0))\n",
        "        plt.title(f\"Epoch {epoch} - Generated Images\")\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{out_dir}/epoch_{epoch}_images.png\")\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "xhQOwUfr22vW"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(train_data, latent_dim: int = 100, hidden_dim: int = 128, learning_rate: float = 0.001, epochs: int = 500, batch_size: int = 128, seed: int = 42):\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    fixed_noise = torch.randn(16, latent_dim).to('cuda')\n",
        "\n",
        "    os.makedirs(\"gan_outputs\", exist_ok=True)\n",
        "\n",
        "    G = Generator(latent_dim, 1, 64).to(device='cuda')\n",
        "    D = Discriminator(1, 64).to(device='cuda')\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Optimizer setup\n",
        "    \"\"\"\n",
        "    optimizer_gen = optim.Adam(G.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "    optimizer_dsc = optim.Adam(D.model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "\n",
        "\n",
        "\n",
        "    loss_func = nn.BCELoss()\n",
        "    gen_loss_class = nn.BCELoss()\n",
        "\n",
        "\n",
        "    epoch = 0\n",
        "\n",
        "    gen_loss_up = []\n",
        "    dsc_loss_up = []\n",
        "\n",
        "    train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for data in train_data_loader:\n",
        "            x_data, x_label = data\n",
        "            # print(x_data.shape)\n",
        "\n",
        "            \"\"\"\n",
        "            Discriminator pass\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "            img_real = x_data.to(device='cuda')\n",
        "            z_fake_latent = torch.randn(batch_size, latent_dim).to(device='cuda')\n",
        "\n",
        "            img_fake = G(z_fake_latent)\n",
        "\n",
        "            # print(img_fake.shape)\n",
        "\n",
        "            \"\"\"\n",
        "            Optimizer step discriminator\n",
        "            \"\"\"\n",
        "\n",
        "            optimizer_dsc.zero_grad()\n",
        "\n",
        "            dsc_out_real = D(img_real)\n",
        "            dsc_labels_real = torch.ones(batch_size, 1).to(device='cuda')\n",
        "\n",
        "            dsc_out_fake = D(img_fake.detach())\n",
        "            dsc_labels_fake = torch.zeros(batch_size, 1).to(device='cuda')\n",
        "\n",
        "            loss_dsc_real = loss_func(dsc_out_real, dsc_labels_real)\n",
        "            loss_dsc_fake = loss_func(dsc_out_fake, dsc_labels_fake)\n",
        "\n",
        "            loss_dsc = (loss_dsc_real + loss_dsc_fake)\n",
        "\n",
        "            dsc_loss_up.append(loss_dsc.item())\n",
        "\n",
        "            loss_dsc.backward()\n",
        "            optimizer_dsc.step()\n",
        "\n",
        "            \"\"\"\n",
        "            Optimizer step generator\n",
        "            \"\"\"\n",
        "\n",
        "            optimizer_gen.zero_grad()\n",
        "\n",
        "            gen_out = D(img_fake)\n",
        "\n",
        "            gen_loss = gen_loss_class(gen_out, dsc_labels_real)\n",
        "\n",
        "            gen_loss_up.append(gen_loss.item())\n",
        "\n",
        "            gen_loss.backward()\n",
        "            optimizer_gen.step()\n",
        "\n",
        "            # print(loss_dsc_real, loss_dsc_fake, gen_loss)\n",
        "\n",
        "        # Logging\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}] | D Loss: {loss_dsc.item():.4f} | G Loss: {gen_loss.item():.4f}\")\n",
        "\n",
        "            plot_generated_images(G, fixed_noise, epoch + 1)\n",
        "            print(f\"D(real): {torch.sigmoid(dsc_out_real).mean().item():.4f}, D(fake): {torch.sigmoid(dsc_out_fake).mean().item():.4f}\")\n",
        "\n",
        "\n",
        "    return G.forward, dsc_loss_up, gen_loss_up"
      ],
      "metadata": {
        "id": "WOAZ0pPWhqHR"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_forward, dsc_loss_up,gen_loss_up  = train_gan(train_dataset, learning_rate=0.1, epochs=100, seed=42)\n",
        "# z = torch.randn(50, 10)\n",
        "# x_gen = gen_forward(z)\n",
        "# print((round(x_gen.mean().item(), 4), round(x_gen.std().item(), 4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3S17x-hhD0h",
        "outputId": "4f4e122c-d430-4a2b-efec-38f15a46a403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] | D Loss: 0.0110 | G Loss: 8.1977\n",
            "D(real): 0.7296, D(fake): 0.5007\n",
            "Epoch [2/100] | D Loss: 0.2027 | G Loss: 7.0988\n",
            "D(real): 0.7103, D(fake): 0.5043\n",
            "Epoch [3/100] | D Loss: 0.2426 | G Loss: 7.3263\n",
            "D(real): 0.7274, D(fake): 0.5249\n",
            "Epoch [4/100] | D Loss: 0.3444 | G Loss: 4.7825\n",
            "D(real): 0.7126, D(fake): 0.5233\n",
            "Epoch [5/100] | D Loss: 0.3917 | G Loss: 4.1064\n",
            "D(real): 0.6905, D(fake): 0.5089\n",
            "Epoch [6/100] | D Loss: 0.5394 | G Loss: 2.6250\n",
            "D(real): 0.6898, D(fake): 0.5271\n",
            "Epoch [7/100] | D Loss: 0.4719 | G Loss: 3.1037\n",
            "D(real): 0.6982, D(fake): 0.5297\n",
            "Epoch [8/100] | D Loss: 0.3968 | G Loss: 3.4179\n",
            "D(real): 0.7116, D(fake): 0.5455\n",
            "Epoch [9/100] | D Loss: 0.5576 | G Loss: 3.8071\n",
            "D(real): 0.7110, D(fake): 0.5636\n",
            "Epoch [10/100] | D Loss: 0.4766 | G Loss: 2.8863\n",
            "D(real): 0.6899, D(fake): 0.5247\n",
            "Epoch [11/100] | D Loss: 0.3972 | G Loss: 4.4867\n",
            "D(real): 0.7106, D(fake): 0.5410\n",
            "Epoch [12/100] | D Loss: 0.4398 | G Loss: 2.8734\n",
            "D(real): 0.7080, D(fake): 0.5411\n",
            "Epoch [13/100] | D Loss: 0.5076 | G Loss: 3.2710\n",
            "D(real): 0.6904, D(fake): 0.5229\n",
            "Epoch [14/100] | D Loss: 0.4224 | G Loss: 3.3169\n",
            "D(real): 0.7125, D(fake): 0.5425\n",
            "Epoch [15/100] | D Loss: 0.4485 | G Loss: 3.9638\n",
            "D(real): 0.6925, D(fake): 0.5246\n",
            "Epoch [16/100] | D Loss: 0.4098 | G Loss: 3.6083\n",
            "D(real): 0.7029, D(fake): 0.5256\n",
            "Epoch [17/100] | D Loss: 0.4608 | G Loss: 3.3817\n",
            "D(real): 0.6906, D(fake): 0.5179\n",
            "Epoch [18/100] | D Loss: 0.3511 | G Loss: 3.8732\n",
            "D(real): 0.7166, D(fake): 0.5391\n",
            "Epoch [19/100] | D Loss: 0.5751 | G Loss: 3.2867\n",
            "D(real): 0.6819, D(fake): 0.5157\n",
            "Epoch [20/100] | D Loss: 0.4970 | G Loss: 3.8576\n",
            "D(real): 0.6938, D(fake): 0.5199\n",
            "Epoch [21/100] | D Loss: 0.3641 | G Loss: 2.9031\n",
            "D(real): 0.7051, D(fake): 0.5295\n",
            "Epoch [22/100] | D Loss: 0.6122 | G Loss: 2.9759\n",
            "D(real): 0.6839, D(fake): 0.5302\n",
            "Epoch [23/100] | D Loss: 0.3750 | G Loss: 3.5466\n",
            "D(real): 0.7069, D(fake): 0.5236\n",
            "Epoch [24/100] | D Loss: 1.8502 | G Loss: 9.7470\n",
            "D(real): 0.6668, D(fake): 0.5357\n",
            "Epoch [25/100] | D Loss: 0.4741 | G Loss: 3.0251\n",
            "D(real): 0.7032, D(fake): 0.5367\n",
            "Epoch [26/100] | D Loss: 0.3594 | G Loss: 2.8175\n",
            "D(real): 0.6978, D(fake): 0.5221\n",
            "Epoch [27/100] | D Loss: 0.4151 | G Loss: 3.3488\n",
            "D(real): 0.7019, D(fake): 0.5294\n",
            "Epoch [28/100] | D Loss: 0.3893 | G Loss: 4.2909\n",
            "D(real): 0.7008, D(fake): 0.5243\n",
            "Epoch [29/100] | D Loss: 0.3221 | G Loss: 4.1948\n",
            "D(real): 0.7076, D(fake): 0.5279\n",
            "Epoch [30/100] | D Loss: 0.5092 | G Loss: 2.9959\n",
            "D(real): 0.7111, D(fake): 0.5460\n",
            "Epoch [31/100] | D Loss: 0.4538 | G Loss: 4.3392\n",
            "D(real): 0.7002, D(fake): 0.5256\n",
            "Epoch [32/100] | D Loss: 0.4929 | G Loss: 3.2380\n",
            "D(real): 0.6842, D(fake): 0.5118\n",
            "Epoch [33/100] | D Loss: 0.3091 | G Loss: 3.9261\n",
            "D(real): 0.7123, D(fake): 0.5268\n",
            "Epoch [34/100] | D Loss: 0.5726 | G Loss: 5.7530\n",
            "D(real): 0.6774, D(fake): 0.5054\n",
            "Epoch [35/100] | D Loss: 0.3534 | G Loss: 3.3108\n",
            "D(real): 0.7033, D(fake): 0.5224\n",
            "Epoch [36/100] | D Loss: 0.2868 | G Loss: 3.8759\n",
            "D(real): 0.7080, D(fake): 0.5193\n",
            "Epoch [37/100] | D Loss: 0.3296 | G Loss: 3.3977\n",
            "D(real): 0.7039, D(fake): 0.5174\n",
            "Epoch [38/100] | D Loss: 0.3797 | G Loss: 4.0555\n",
            "D(real): 0.6985, D(fake): 0.5222\n",
            "Epoch [39/100] | D Loss: 0.4657 | G Loss: 3.7508\n",
            "D(real): 0.7221, D(fake): 0.5502\n",
            "Epoch [40/100] | D Loss: 0.2333 | G Loss: 4.3885\n",
            "D(real): 0.7146, D(fake): 0.5236\n",
            "Epoch [41/100] | D Loss: 0.3027 | G Loss: 3.9801\n",
            "D(real): 0.7111, D(fake): 0.5285\n",
            "Epoch [42/100] | D Loss: 0.3255 | G Loss: 5.3689\n",
            "D(real): 0.7098, D(fake): 0.5303\n",
            "Epoch [43/100] | D Loss: 0.3272 | G Loss: 3.4103\n",
            "D(real): 0.7218, D(fake): 0.5383\n",
            "Epoch [44/100] | D Loss: 0.2944 | G Loss: 4.4882\n",
            "D(real): 0.7106, D(fake): 0.5220\n",
            "Epoch [45/100] | D Loss: 0.5296 | G Loss: 3.7686\n",
            "D(real): 0.6941, D(fake): 0.5157\n",
            "Epoch [46/100] | D Loss: 0.3272 | G Loss: 3.6677\n",
            "D(real): 0.7259, D(fake): 0.5447\n",
            "Epoch [47/100] | D Loss: 0.2454 | G Loss: 4.5442\n",
            "D(real): 0.7184, D(fake): 0.5230\n",
            "Epoch [48/100] | D Loss: 0.3492 | G Loss: 2.8268\n",
            "D(real): 0.7015, D(fake): 0.5190\n",
            "Epoch [49/100] | D Loss: 0.3178 | G Loss: 4.0932\n",
            "D(real): 0.7025, D(fake): 0.5050\n",
            "Epoch [50/100] | D Loss: 0.3697 | G Loss: 3.0980\n",
            "D(real): 0.7108, D(fake): 0.5308\n",
            "Epoch [51/100] | D Loss: 0.6543 | G Loss: 4.7164\n",
            "D(real): 0.6803, D(fake): 0.5041\n",
            "Epoch [52/100] | D Loss: 0.3019 | G Loss: 3.2499\n",
            "D(real): 0.7052, D(fake): 0.5178\n",
            "Epoch [53/100] | D Loss: 0.5410 | G Loss: 3.6159\n",
            "D(real): 0.7113, D(fake): 0.5417\n",
            "Epoch [54/100] | D Loss: 0.5205 | G Loss: 4.5256\n",
            "D(real): 0.7044, D(fake): 0.5269\n",
            "Epoch [55/100] | D Loss: 0.4874 | G Loss: 3.4844\n",
            "D(real): 0.6900, D(fake): 0.5061\n",
            "Epoch [56/100] | D Loss: 0.3684 | G Loss: 3.3316\n",
            "D(real): 0.7214, D(fake): 0.5439\n",
            "Epoch [57/100] | D Loss: 0.2876 | G Loss: 3.9021\n",
            "D(real): 0.7168, D(fake): 0.5304\n",
            "Epoch [58/100] | D Loss: 0.2307 | G Loss: 3.7535\n",
            "D(real): 0.7195, D(fake): 0.5212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "307pEbNAthj5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}