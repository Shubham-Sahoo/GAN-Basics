{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWCOXk1s95x2h2QWfZQajw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubham-Sahoo/GAN-Basics/blob/main/WGAN-GP/WGAN_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PE-Kqr5-gJUS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import grad\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transformation to apply to the images (e.g., convert to tensor)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])  # scale to [-1, 1]\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of test samples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "ZF2lcdYpgK6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccfb9d54-06bb-4707-fd45-681a1635c28b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 480kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.44MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.32MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 60000\n",
            "Number of test samples: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_dataset:\n",
        "    print(x[0].shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwQPQl7QpUpw",
        "outputId": "5f35e283-6972-405f-bcd3-32f1572758e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, img_channels=1, feature_maps=64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.latent_linear = nn.Linear(latent_dim, feature_maps * 7*7)\n",
        "        self.unflatten = nn.Unflatten(1, (feature_maps, 7, 7))\n",
        "        self.conv_up1 = nn.ConvTranspose2d(feature_maps, feature_maps // 2, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv_up2 = nn.ConvTranspose2d(feature_maps // 2, img_channels, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "        self.relu1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.relu2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.tanh1 = nn.Tanh()\n",
        "\n",
        "        self.batchnorm1 = nn.BatchNorm2d(feature_maps // 2)\n",
        "\n",
        "\n",
        "    def forward(self, z):\n",
        "\n",
        "        out = self.latent_linear(z)\n",
        "        out = self.relu1(out)\n",
        "        out = self.unflatten(out)\n",
        "\n",
        "        out = self.conv_up1(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.batchnorm1(out)\n",
        "\n",
        "        out = self.conv_up2(out)\n",
        "        out = self.tanh1(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fej6Qm6Lg9rY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = Generator(100, 1, 64)\n",
        "x = torch.tensor(np.ones((1,100)), dtype=torch.float)\n",
        "G(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZx56X7jjlHj",
        "outputId": "6ec54348-cfd1-4bb0-91a1-1571135ae98f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_channels=1, feature_maps=64):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, feature_maps, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(feature_maps, feature_maps*2, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(feature_maps*2*7*7, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "3oguQ4V0hsaa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator(1, 64)\n",
        "x = torch.tensor(np.ones((3,1,28,28)), dtype=torch.float)\n",
        "D(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yun_LQ_bjkVN",
        "outputId": "08bd83d0-fd29-4b70-ebef-ebbae8f93af4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generated_images(generator, noise, epoch, out_dir=\"wgan_gp_outputs\"):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        fake_images = generator(noise).cpu()\n",
        "\n",
        "    # For 1D vectors (e.g., Gaussian): Plot as line chart\n",
        "    if fake_images.dim() == 2:  # Shape: [batch_size, features]\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        for i in range(min(8, fake_images.size(0))):\n",
        "            plt.plot(fake_images[i].numpy(), label=f\"Sample {i}\")\n",
        "        plt.title(f\"Generated Samples at Epoch {epoch}\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{out_dir}/epoch_{epoch}_lines.png\")\n",
        "        plt.close()\n",
        "\n",
        "    # For image data (e.g., MNIST or CIFAR): Show grid\n",
        "    elif fake_images.dim() == 4:  # Shape: [B, C, H, W]\n",
        "        from torchvision.utils import make_grid\n",
        "        grid = make_grid(fake_images, nrow=4, normalize=True, value_range=(-1, 1))\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(grid.permute(1, 2, 0))\n",
        "        plt.title(f\"Epoch {epoch} - Generated Images\")\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{out_dir}/epoch_{epoch}_images.png\")\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "xhQOwUfr22vW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient_penalty(D, real_samples, fake_samples, device):\n",
        "    alpha = torch.rand(real_samples.size(0), 1, 1, 1).to(device)\n",
        "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
        "\n",
        "    d_interpolates = D(interpolates)\n",
        "\n",
        "    # We assume output is (batch_size, 1)\n",
        "    grad_outputs = torch.ones_like(d_interpolates).to(device)\n",
        "\n",
        "    gradients = grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=grad_outputs,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]  # gradient w.r.t. interpolated images\n",
        "\n",
        "    gradients = gradients.view(gradients.size(0), -1)  # flatten\n",
        "    grad_norm = gradients.norm(2, dim=1)  # L2 norm per sample\n",
        "\n",
        "    penalty = ((grad_norm - 1) ** 2).mean()\n",
        "    return penalty"
      ],
      "metadata": {
        "id": "MRNVxvI56P-e"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(train_data, latent_dim: int = 100, hidden_dim: int = 128, learning_rate: float = 0.001, epochs: int = 500, batch_size: int = 128, seed: int = 42):\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    device = 'cuda'\n",
        "\n",
        "    fixed_noise = torch.randn(16, latent_dim).to(device)\n",
        "\n",
        "    os.makedirs(\"wgan_gp_outputs\", exist_ok=True)\n",
        "\n",
        "    G = Generator(latent_dim, 1, 64).to(device=device)\n",
        "    D = Discriminator(1, 64).to(device=device)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Optimizer setup\n",
        "    \"\"\"\n",
        "    optimizer_gen = optim.Adam(G.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "    optimizer_dsc = optim.Adam(D.model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "\n",
        "\n",
        "\n",
        "    # loss_func = nn.L1Loss()\n",
        "    # gen_loss_class = nn.BCELoss()\n",
        "\n",
        "\n",
        "    epoch = 0\n",
        "\n",
        "    gen_loss_up = []\n",
        "    dsc_loss_up = []\n",
        "\n",
        "    train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for data in train_data_loader:\n",
        "            x_data, x_label = data\n",
        "            # print(x_data.shape)\n",
        "\n",
        "            \"\"\"\n",
        "            Discriminator pass\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "            img_real = x_data.to(device=device)\n",
        "            z_fake_latent = torch.randn(batch_size, latent_dim).to(device=device)\n",
        "\n",
        "            img_fake = G(z_fake_latent)\n",
        "\n",
        "            # print(img_fake.shape)\n",
        "\n",
        "            \"\"\"\n",
        "            Optimizer step discriminator\n",
        "            \"\"\"\n",
        "\n",
        "            optimizer_dsc.zero_grad()\n",
        "\n",
        "            dsc_out_real = D(img_real)\n",
        "            dsc_labels_real = torch.ones(batch_size, 1).to(device=device)\n",
        "\n",
        "            dsc_out_fake = D(img_fake.detach())\n",
        "            dsc_labels_fake = torch.zeros(batch_size, 1).to(device=device)\n",
        "\n",
        "            # loss_dsc_real = dsc_out_real, dsc_labels_real\n",
        "            # loss_dsc_fake = loss_func(dsc_out_fake, dsc_labels_fake)\n",
        "\n",
        "            gp = compute_gradient_penalty(D, img_real.detach(), img_fake.detach(), device)\n",
        "\n",
        "            loss_dsc = -torch.mean(dsc_out_real) + torch.mean(dsc_out_fake) + 10 * gp\n",
        "\n",
        "            dsc_loss_up.append(loss_dsc.item())\n",
        "\n",
        "            loss_dsc.backward()\n",
        "            optimizer_dsc.step()\n",
        "\n",
        "            \"\"\"\n",
        "            Optimizer step generator\n",
        "            \"\"\"\n",
        "\n",
        "            optimizer_gen.zero_grad()\n",
        "\n",
        "            gen_out = D(img_fake)\n",
        "\n",
        "            gen_loss = -torch.mean(gen_out)\n",
        "\n",
        "            gen_loss_up.append(gen_loss.item())\n",
        "\n",
        "            gen_loss.backward()\n",
        "            optimizer_gen.step()\n",
        "\n",
        "            # print(loss_dsc_real, loss_dsc_fake, gen_loss)\n",
        "\n",
        "        # Logging\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}] | D Loss: {loss_dsc.item():.4f} | G Loss: {gen_loss.item():.4f}\")\n",
        "\n",
        "            plot_generated_images(G, fixed_noise, epoch + 1)\n",
        "            print(f\"D(real): {torch.sigmoid(dsc_out_real).mean().item():.4f}, D(fake): {torch.sigmoid(dsc_out_fake).mean().item():.4f}\")\n",
        "\n",
        "\n",
        "    return G.forward, dsc_loss_up, gen_loss_up"
      ],
      "metadata": {
        "id": "WOAZ0pPWhqHR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_forward, dsc_loss_up,gen_loss_up  = train_gan(train_dataset, learning_rate=0.1, epochs=100, seed=42)\n",
        "# z = torch.randn(50, 10)\n",
        "# x_gen = gen_forward(z)\n",
        "# print((round(x_gen.mean().item(), 4), round(x_gen.std().item(), 4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3S17x-hhD0h",
        "outputId": "49721f97-a234-4440-8c04-a869f3ebb7cc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] | D Loss: -2.1873 | G Loss: -4.6223\n",
            "D(real): 0.9976, D(fake): 0.9813\n",
            "Epoch [2/100] | D Loss: -3.3189 | G Loss: -9.3394\n",
            "D(real): 1.0000, D(fake): 0.9996\n",
            "Epoch [3/100] | D Loss: -2.9706 | G Loss: -11.5141\n",
            "D(real): 1.0000, D(fake): 0.9999\n",
            "Epoch [4/100] | D Loss: -1.7957 | G Loss: -14.1274\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [5/100] | D Loss: -0.8474 | G Loss: -21.6518\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [6/100] | D Loss: -0.5986 | G Loss: -31.3953\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [7/100] | D Loss: -0.6334 | G Loss: -13.1327\n",
            "D(real): 0.9999, D(fake): 0.9996\n",
            "Epoch [8/100] | D Loss: -1.8862 | G Loss: -47.5645\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [9/100] | D Loss: -0.5639 | G Loss: -29.2751\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [10/100] | D Loss: -0.1498 | G Loss: -21.9044\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [11/100] | D Loss: -1.5179 | G Loss: -5.8501\n",
            "D(real): 0.9956, D(fake): 0.9843\n",
            "Epoch [12/100] | D Loss: -0.4006 | G Loss: -24.5653\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [13/100] | D Loss: -0.2579 | G Loss: -5.7422\n",
            "D(real): 0.9983, D(fake): 0.9990\n",
            "Epoch [14/100] | D Loss: -0.9078 | G Loss: -32.5743\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [15/100] | D Loss: -0.4820 | G Loss: -42.1265\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [16/100] | D Loss: -1.0492 | G Loss: -42.9776\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [17/100] | D Loss: -0.4455 | G Loss: 2.2655\n",
            "D(real): 0.1755, D(fake): 0.1320\n",
            "Epoch [18/100] | D Loss: -0.4599 | G Loss: -29.6413\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [19/100] | D Loss: -0.6374 | G Loss: -52.4176\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [20/100] | D Loss: -0.6022 | G Loss: -60.9797\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [21/100] | D Loss: -0.0410 | G Loss: -65.6881\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [22/100] | D Loss: -0.5410 | G Loss: -16.4807\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [23/100] | D Loss: 0.1972 | G Loss: -45.3818\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [24/100] | D Loss: -0.0472 | G Loss: -6.8493\n",
            "D(real): 0.9994, D(fake): 0.9990\n",
            "Epoch [25/100] | D Loss: -0.7508 | G Loss: -67.1929\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [26/100] | D Loss: -0.4901 | G Loss: -32.2789\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [27/100] | D Loss: -0.0965 | G Loss: -57.6827\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [28/100] | D Loss: 0.0747 | G Loss: -47.5369\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [29/100] | D Loss: -0.5749 | G Loss: -67.2710\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [30/100] | D Loss: 0.0785 | G Loss: -33.8211\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [31/100] | D Loss: -3.4869 | G Loss: 8.3162\n",
            "D(real): 0.0909, D(fake): 0.0198\n",
            "Epoch [32/100] | D Loss: -0.5855 | G Loss: -34.6471\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [33/100] | D Loss: -0.5747 | G Loss: -59.0149\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [34/100] | D Loss: 0.3443 | G Loss: -21.3637\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [35/100] | D Loss: -0.4746 | G Loss: -11.1408\n",
            "D(real): 0.9991, D(fake): 0.9980\n",
            "Epoch [36/100] | D Loss: -0.8611 | G Loss: -38.6776\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [37/100] | D Loss: 0.3772 | G Loss: -82.3547\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [38/100] | D Loss: 0.5753 | G Loss: -65.8638\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [39/100] | D Loss: -1.0443 | G Loss: -99.2216\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [40/100] | D Loss: -0.2480 | G Loss: -64.1748\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [41/100] | D Loss: -0.2846 | G Loss: -45.5408\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [42/100] | D Loss: -0.5117 | G Loss: -67.2165\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [43/100] | D Loss: -0.2289 | G Loss: -145.0081\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [44/100] | D Loss: -1.1337 | G Loss: -36.8170\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [45/100] | D Loss: -0.3372 | G Loss: -31.4383\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [46/100] | D Loss: -1.1657 | G Loss: -25.3645\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [47/100] | D Loss: -0.3013 | G Loss: -57.7531\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [48/100] | D Loss: -0.4299 | G Loss: -68.9308\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [49/100] | D Loss: 0.0641 | G Loss: -32.7915\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [50/100] | D Loss: 0.2176 | G Loss: -49.2356\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [51/100] | D Loss: -0.3868 | G Loss: -79.5397\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [52/100] | D Loss: -0.7847 | G Loss: -62.3623\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [53/100] | D Loss: -1.0098 | G Loss: -46.1475\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [54/100] | D Loss: -0.3825 | G Loss: -16.5318\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [55/100] | D Loss: -1.2304 | G Loss: -11.9208\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [56/100] | D Loss: -0.6206 | G Loss: -116.9981\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [57/100] | D Loss: 0.4981 | G Loss: -67.2940\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [58/100] | D Loss: -0.5477 | G Loss: -24.0000\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [59/100] | D Loss: -0.2312 | G Loss: -18.5994\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [60/100] | D Loss: -0.3672 | G Loss: -30.6427\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [61/100] | D Loss: 0.5997 | G Loss: -20.0626\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [62/100] | D Loss: 0.0583 | G Loss: -22.4077\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [63/100] | D Loss: -0.1065 | G Loss: -114.5632\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [64/100] | D Loss: -0.3563 | G Loss: -76.5374\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [65/100] | D Loss: -0.6648 | G Loss: -24.8729\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [66/100] | D Loss: -1.1639 | G Loss: -50.0834\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [67/100] | D Loss: -1.1086 | G Loss: -16.6490\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [68/100] | D Loss: -0.5495 | G Loss: -32.4574\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [69/100] | D Loss: -0.3823 | G Loss: -25.0998\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [70/100] | D Loss: -0.9736 | G Loss: -72.0855\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [71/100] | D Loss: 0.3642 | G Loss: -78.9135\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [72/100] | D Loss: -0.6930 | G Loss: -29.7527\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [73/100] | D Loss: -0.2706 | G Loss: -71.5996\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [74/100] | D Loss: -0.4416 | G Loss: -59.0628\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [75/100] | D Loss: 1.7773 | G Loss: 27.3006\n",
            "D(real): 0.0000, D(fake): 0.0000\n",
            "Epoch [76/100] | D Loss: 1.7992 | G Loss: 7.3018\n",
            "D(real): 0.0002, D(fake): 0.0006\n",
            "Epoch [77/100] | D Loss: -0.5808 | G Loss: -59.5816\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [78/100] | D Loss: -0.9503 | G Loss: -93.5737\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [79/100] | D Loss: -0.2145 | G Loss: -27.8119\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [80/100] | D Loss: -0.1156 | G Loss: -63.9227\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [81/100] | D Loss: -0.1578 | G Loss: -71.3415\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [82/100] | D Loss: -0.5377 | G Loss: -6.9398\n",
            "D(real): 0.9984, D(fake): 0.9981\n",
            "Epoch [83/100] | D Loss: -0.6345 | G Loss: -25.6892\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [84/100] | D Loss: -0.0410 | G Loss: -41.5340\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [85/100] | D Loss: -0.2539 | G Loss: -47.2446\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [86/100] | D Loss: -0.3636 | G Loss: -24.0913\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [87/100] | D Loss: 0.3831 | G Loss: -21.9869\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [88/100] | D Loss: -1.0884 | G Loss: -186.8804\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [89/100] | D Loss: -0.0107 | G Loss: -30.4153\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [90/100] | D Loss: 0.1535 | G Loss: -31.1766\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [91/100] | D Loss: 0.3689 | G Loss: -15.4536\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [92/100] | D Loss: -0.3904 | G Loss: -50.6393\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [93/100] | D Loss: -0.6574 | G Loss: -65.6477\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [94/100] | D Loss: 0.0156 | G Loss: -65.1408\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [95/100] | D Loss: -0.6240 | G Loss: -40.6473\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [96/100] | D Loss: -0.6485 | G Loss: -50.7344\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [97/100] | D Loss: -0.1897 | G Loss: -86.3709\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [98/100] | D Loss: -0.0340 | G Loss: -86.8023\n",
            "D(real): 1.0000, D(fake): 1.0000\n",
            "Epoch [99/100] | D Loss: -1.3534 | G Loss: -13.5866\n",
            "D(real): 1.0000, D(fake): 0.9999\n",
            "Epoch [100/100] | D Loss: -0.3658 | G Loss: -24.8461\n",
            "D(real): 1.0000, D(fake): 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio.v2 as imageio\n",
        "import os\n",
        "from natsort import natsorted\n",
        "\n",
        "image_folder = 'wgan_outputs'\n",
        "output_gif = 'wgan_training.gif'\n",
        "\n",
        "images = []\n",
        "filenames = natsorted([f for f in os.listdir(image_folder) if f.endswith('.png')])\n",
        "\n",
        "for filename in filenames:\n",
        "    image_path = os.path.join(image_folder, filename)\n",
        "    images.append(imageio.imread(image_path))\n",
        "\n",
        "# Save GIF (duration per frame in seconds)\n",
        "imageio.mimsave(output_gif, images, duration=0.4)\n",
        "\n",
        "print(f\"GIF saved as {output_gif}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "307pEbNAthj5",
        "outputId": "5a87600d-19b9-4f71-a5b7-bcbb7f27caa8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GIF saved as wgan_training.gif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ci3zt1VVGQmI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}